Prompt:

You are a systems-engineering AI tasked with planning a complete C-based project that integrates a custom, zero-copy TCP/IP stack with a Redis-like in-memory database. Focus on leveraging C’s low-level control to maximize speed and minimize latency by eliminating OS bottlenecks. Your plan should prioritize clarity and learning (with emphasis on performance and scalability), and use well-studied algorithms. Where there are choices with minor impact, prefer the simpler solution. Provide structure, key algorithms/data-structures, and measurable targets.

Objectives and Overview

Bypass the Kernel for Speed: Architect the system so that packets flow directly between the NIC and user code. Standard raw sockets incur kernel context switches and copies
stackoverflow.com
; instead use a kernel-bypass approach (e.g. Linux AF_PACKET or AF_XDP, or a framework like DPDK) to eliminate these costs
medium.com
stackoverflow.com
. The goal is “zero-copy” I/O: NIC→user-space memory with minimal OS intervention
medium.com
.

Full TCP/IP Stack in Userspace: Implement the Ethernet/IP/TCP protocol logic in C. This includes parsing/building headers (Ethernet, IPv4/ARP, TCP checksums, 3-way handshake, TCP state machine, sliding window, retransmits). This deep exposure to bit-level protocol details (endianness, packing) is a core learning goal. The stack should run over raw interfaces (TAP/AF_PACKET) for initial testing, with a path to high-performance AF_XDP/DPDK if needed.

RESP Protocol for Client I/O: Support the Redis Serialization Protocol (RESP2) for client commands. Implement a streaming parser that reads length-prefixed bulk strings and arrays with minimal overhead. Avoid unnecessary parsing of payload data (use the length prefixes to read raw value bytes directly). Support pipelining and handle basic RESP types (bulk strings, integers, simple strings, errors). (RESP3 features can be deferred.)

Core Data Engine (Redis-like): Build an in-memory KV engine with main datatypes (strings, lists, hashes, sorted sets, streams). Focus first on a key-value hash map and list data type. Ensure all commands (PING, ECHO, SET, GET, LPUSH/POP, LRANGE, etc.) work correctly. Use efficient, cache-friendly data structures (below). The engine should be sharded per CPU/core for concurrency, so that each shard handles one partition of the keyspace without locks for common ops.

Performance Goals: Aim for deterministic low tail-latency and high throughput. For example, target orders-of-magnitude reduction in packet-processing overhead compared to a kernel-stack (e.g. benchmark directly against Linux TCP+Redis). Use techniques that keep working data in L1/L2 cache (e.g. fixed-size packed structs, flat arrays)
thenumb.at
matt.sh
.

Key Components and Algorithms

Network I/O (Kernel-bypass) – Use a raw packet interface. For a simple baseline, bind a raw AF_PACKET/TAP socket to an interface; for production-grade speed, use AF_XDP or DPDK with mmap/UMEM. AF_XDP is Linux’s high-performance packet API (via eBPF) and can sustain >10 Gbps with minimal copies
stackoverflow.com
stackoverflow.com
. Design the code so that the NIC rings (RX/TX) are memory-mapped into user space for zero-copy reads/writes
medium.com
.

Packet Parsing – Parse raw Ethernet frames into IP/TCP. Define packed C structs matching the protocol headers (Ethernet, IPv4 (RFC 791), TCP (RFC 793)). Carefully handle endianness (use htons, ntohl, etc.). Compute and verify checksums with bitwise ops. For learning, ensure code reads header lengths (e.g. ihl field) and does pointer arithmetic to locate TCP data. Include ARP/ICMP to enable basic ping functionality. Verify that a ping to the virtual IP elicits a correct ICMP Echo Reply.

Custom TCP Stack – Implement a minimal TCP state machine: SYN, SYN-ACK, ACK handshake, FIN close. Manage sequence numbers and reordering (use a ring buffer per connection to reorder out-of-order segments). Implement a sliding window and retransmit timer (you’ll need to track unACKed data and timeouts). Use a circular buffer for the send/receive queues to avoid malloc on each segment. (This part is the most complex; for faster progress you may limit to a single connection or assume in-order delivery at first.)

RESP Command Handling – Once the TCP stream is established, process incoming data as a RESP request stream. Parse the array-of-bulk-strings command format. Dispatch commands to handlers (PING, ECHO, SET, GET, etc.). Encode replies (simple string “+OK\r\n”, integer “:123\r\n”, bulk strings, etc.). Because RESP is length-prefixed and binary-safe, design the parser as a state machine that reads lengths and then reads exact payload bytes. This avoids rescanning data or splitting strings.

Hash Table (Key-Value Store) – Implement the main key→value map with an open-addressing hash table (flat array) for cache efficiency
thenumb.at
. Use power-of-two size and hash(key) & (N-1) for indexing. Use Robin Hood linear probing with backshift deletion: on insert, if the new key has probed more times than an occupant, swap them, thereby “stealing” the longest probe chains
thenumb.at
. This yields very low variance in lookup time (good 99th-percentile) while keeping average probes close to optimal. Periodically resize (double) when load >70%.

List Data Type – For Redis-style lists, use a Quicklist: a linked list of small “ziplist” arrays
matt.sh
. Each node contains an array of elements (a compact contiguous block, like a packed struct list). When one node fills, allocate a new one. This gives O(1) push/pop at head/tail and good spatial locality for traversal
matt.sh
. In simple mode, you can start with a basic doubly-linked list or array list; optimize to quicklist later.

Sorted Set – Store sorted sets as a skiplist + hash table
redis.io
. Keep a hashtable mapping member→score for O(1) score updates, and a skiplist of (score,member) for ordered iteration. This yields O(log N) add/remove/range queries. Redis uses exactly this approach
redis.io
. You can defer sorted-set implementation until the core works, but plan for it in design.

Expiration Timers – For key expiry, track per-key TTL timestamps. Use a min-heap or a hashed timing wheel structure to efficiently expire keys. A timing wheel offers amortized O(1) operations for inserting/canceling timers and stepping to the next deadline, which is ideal for many expirations. (Bibliographic note: hashed wheels are classic for high-scale timers.)

Concurrency & Sharding – Run the server as a multi-threaded application with one thread (or event loop) per CPU core. Shard the keyspace by hashing (e.g. key→(hash % num_shards)). Each shard/thread owns its own hash table and data-structure instances with minimal locking. Inter-shard transactions or multi-key commands must acquire locks in a consistent global order to avoid deadlock. For I/O, either use one epoll/kqueue loop per thread (with SO_REUSEPORT) or a shared acceptor that dispatches new connections round-robin. Blocking commands (like BLPOP) can suspend the connection context until data is available.

Persistence and Replication (Optional Targets) – Once the core is running, optionally add AOF persistence: append each write command to a file for durability, optionally fsync’d periodically. Implement RDB-style snapshots by forking the process and writing the data to disk in the child. For replication, maintain a replication log buffer so replicas can PSYNC partial resyncs. These are advanced features; focus first on correct in-memory behavior.

Milestones and Development Plan

Basic RESP Server (Core MVP): Implement a single-threaded C server that uses standard TCP sockets (through epoll) and parses RESP commands. Support PING, ECHO, SET, GET in an in-memory hash map. This proves the core protocol logic.

Efficient Hash Table: Replace the simple map with a flat Robin-Hood hash table (using the algorithm in
thenumb.at
thenumb.at
). Benchmark ops/sec and ensure low tail latency on lookups.

User-Space Packet I/O: Move from TCP sockets to raw packet mode. Open an AF_PACKET socket (or TAP device) bound to an interface. Begin reading Ethernet frames in C, filter out ARP/IP, and feed packet bytes to your IP/TCP parser. Verify you can handle a simple “ping” and see ARP replies. This step demonstrates raw frame I/O.

Complete TCP Stack: Extend the network code to implement TCP: respond to SYNs, track sequence numbers, ACK, reassemble streams, and pass the byte stream to the RESP parser. At this point, you have a full userspace network pipeline. Test with standard Redis CLI by adjusting Linux routing (e.g. route to the virtual IP).

Advanced Data Structures: Implement lists (quicklist) and sorted sets (skiplist+hash) within the engine. Support LRANGE, LPOP, ZADD, ZRANGE. Measure performance. Optimize as needed (e.g. preallocate nodes, minimize mallocs).

Concurrency and Sharding: Convert the single-threaded design into a multi-threaded, sharded server. Use one thread/epoll per shard. Test concurrent client workloads (e.g. multiple redis-benchmark clients) and verify linear scaling.

Optimization and Tuning: Profile the running system. Use large batches of reads, enable aio with sendmmsg/recvmmsg or writev for sending multiple frames at once. Tune data layouts (e.g. __attribute__((packed)) structs for no padding
stackoverflow.com
, align hot arrays on cache lines). Optionally switch to AF_XDP/DPDK for NIC I/O to compare performance.

Benchmarking: Continuously measure throughput and latency at each phase. Compare against a stock Linux TCP+Redis server: measure context-switch counts and cycles per packet
stackoverflow.com
. Target microsecond-level frame processing.

Documentation and Testing: Write clear documentation of the design (struct layouts, protocol flow) and comprehensive tests (unit tests for data structures, fuzz the RESP parser, end-to-end functional tests).

Pivot Points and Simplifications

Socket vs DPDK: For raw I/O, AF_PACKET (raw socket) is simpler to code but still uses kernel for ring management. If ease-of-development is key, start with AF_PACKET/TAP. For maximum throughput, upgrade to AF_XDP/DPDK (zero-copy) in a second iteration
stackoverflow.com
medium.com
.

Event Loop vs Thread Pool: You can use a simple epoll-based event loop (single-thread or N threads) for concurrency. An alternative is io_uring (Linux AIO) or a thread-per-connection model, but epoll is proven and simpler.

Data Structures: A naive approach would use C++ std::unordered_map or linked lists. However, we intentionally implement hash table and quicklist ourselves to learn. If time is short, a simple chained hash or even glib collections can boot-strap functionality, then optimize later.

Protocol Version: RESP2 is easier (used by Redis 2.x-6.x) and fully sufficient. RESP3 adds new types (NULLs, BOOLs, MAP, etc.) but complicates parsing. You can implement only RESP2 first, adding RESP3 support later if needed.

Libraries and Caution: Use the C standard library and POSIX APIs for networking (socket, epoll, etc.). You may use a high-performance malloc (jemalloc) or a small custom pool to reduce allocation overhead, but avoid large frameworks. For checksums/CRC, coding manually is educational; using a tested library (e.g. zlib’s CRC32) is also acceptable.

Key Guidelines and Targets

Keep code well-commented and modular (e.g. separate IP layer, TCP layer, RESP parser, data structures). This is a learning-focused project.

Emphasize cache locality: store packet buffers, hash table entries, and list nodes in contiguous memory when possible
thenumb.at
matt.sh
.

Verify correctness at each stage: e.g., unit-test the TCP ACK logic, verify list operations with small examples, etc.

Measure performance: use tools like redis-benchmark or custom packet generators. For example, show that bypassing the kernel eliminates two context switches per packet
stackoverflow.com
.

Always consider the simpler alternative first: if an advanced technique (e.g. vectorized hashing, custom allocator) offers marginal gain, prefer a straightforward implementation. Then document how it could be improved.

By following these guidelines—using zero-copy networking, proven data structures (Robin Hood hash
thenumb.at
, quicklist
matt.sh
, skiplist+hash
redis.io
), and a clear roadmap—you will build a comprehensive, high-performance project. Show the detailed design and steps, and highlight where you use or could use modern optimizations for throughput and efficiency. Use the citations above for reference to known best practices and algorithms.